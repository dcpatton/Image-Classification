{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_tf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/0MQiXkIh6jtS+TH2CqC6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcpatton/Image-Classification/blob/master/cifar10_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Of2BMDeyjMX"
      },
      "source": [
        "# Objective\n",
        "\n",
        "\n",
        "\n",
        "> Just a simple example of image classification with a CNN in TensorFlow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-iahbX8dFXL",
        "outputId": "add90da5-7e31-4fa4-e91a-4ce25bae23f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "seed = 52\n",
        "tf.random.set_seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_v1V8LEy3ut"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdoXXxdZdSpk"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZiu0IFEdael",
        "outputId": "b08d8563-f70b-4bd1-d7b2-457f906ec813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlApp8dxy7Ws"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iCuj6uNHZeQ"
      },
      "source": [
        "normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
        "normalizer.adapt(train_images)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DlPei_tdgwB",
        "outputId": "09c0e978-6cb2-4385-ac3c-763c736a79c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPool2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, RandomRotation, RandomCrop\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomContrast, RandomFlip, RandomZoom, RandomTranslation\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "inp = Input(shape=(32, 32, 3), name='inp', dtype=tf.float32)\n",
        "# x = RandomContrast(0.05, seed=seed)(inp)\n",
        "x = RandomRotation(0.05, seed=seed)(inp)\n",
        "x = RandomFlip(mode='horizontal', seed=seed)(x)\n",
        "x = RandomZoom(height_factor=0.15, width_factor=0.15, seed=seed)(x)\n",
        "x = RandomTranslation(height_factor=0.1, width_factor=0.1, seed=seed)(x)\n",
        "x = RandomCrop(30, 30, seed=seed)(x)\n",
        "# x = Rescaling(scale=1./255, offset=0.)(x)\n",
        "x = normalizer(x)\n",
        "\n",
        "x = Conv2D(32, 3, activation='elu', padding='valid')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, 3, activation='elu', padding='valid')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Conv2D(128, 3, activation='elu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, 3, activation='elu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Conv2D(512, 3, activation='elu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(1024, 3, activation='elu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "# x = Dense(128, activation='relu')(x)\n",
        "# x = Dropout(0.25)(x)\n",
        "out = Dense(10, activation='softmax', name='out')(x)\n",
        "\n",
        "model = Model(inputs=[inp], outputs=[out])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), \n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inp (InputLayer)             [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "random_rotation (RandomRotat (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "random_flip (RandomFlip)     (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "random_zoom (RandomZoom)     (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "random_translation (RandomTr (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "random_crop (RandomCrop)     (None, 30, 30, 3)         0         \n",
            "_________________________________________________________________\n",
            "normalization (Normalization (None, 30, 30, 3)         7         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 11, 11, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 9, 9, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2, 2, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "out (Dense)                  (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 7,347,665\n",
            "Trainable params: 7,343,626\n",
            "Non-trainable params: 4,039\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3U4yauay-SL"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hby3FQaCeAPE",
        "outputId": "641d6193-4418-43b7-def2-9becc579f253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filepath = 'model.h5'\n",
        "mc = tf.keras.callbacks.ModelCheckpoint(filepath, save_best_only=True, \n",
        "                                        save_weights_only=True)\n",
        "es = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1)\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=200, \n",
        "                    validation_data=(test_images, test_labels), \n",
        "                    callbacks=[mc, es], verbose=1, batch_size=32)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.7482 - acc: 0.3876 - val_loss: 1.3442 - val_acc: 0.5149\n",
            "Epoch 2/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.3253 - acc: 0.5276 - val_loss: 1.0702 - val_acc: 0.6223\n",
            "Epoch 3/200\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1234 - acc: 0.6041 - val_loss: 1.0185 - val_acc: 0.6473\n",
            "Epoch 4/200\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9961 - acc: 0.6550 - val_loss: 0.8613 - val_acc: 0.7000\n",
            "Epoch 5/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.9029 - acc: 0.6851 - val_loss: 0.7941 - val_acc: 0.7303\n",
            "Epoch 6/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.8433 - acc: 0.7112 - val_loss: 0.7325 - val_acc: 0.7585\n",
            "Epoch 7/200\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7853 - acc: 0.7292 - val_loss: 0.7022 - val_acc: 0.7708\n",
            "Epoch 8/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.7406 - acc: 0.7443 - val_loss: 0.6806 - val_acc: 0.7722\n",
            "Epoch 9/200\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7003 - acc: 0.7576 - val_loss: 0.7138 - val_acc: 0.7677\n",
            "Epoch 10/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.6865 - acc: 0.7646 - val_loss: 0.6330 - val_acc: 0.7840\n",
            "Epoch 11/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.6454 - acc: 0.7759 - val_loss: 0.5705 - val_acc: 0.8071\n",
            "Epoch 12/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.6249 - acc: 0.7853 - val_loss: 0.5819 - val_acc: 0.8028\n",
            "Epoch 13/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.6013 - acc: 0.7931 - val_loss: 0.5785 - val_acc: 0.8068\n",
            "Epoch 14/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5782 - acc: 0.8004 - val_loss: 0.5893 - val_acc: 0.8048\n",
            "Epoch 15/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5568 - acc: 0.8082 - val_loss: 0.5387 - val_acc: 0.8134\n",
            "Epoch 16/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5347 - acc: 0.8150 - val_loss: 0.5706 - val_acc: 0.8201\n",
            "Epoch 17/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5177 - acc: 0.8215 - val_loss: 0.5707 - val_acc: 0.8120\n",
            "Epoch 18/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5034 - acc: 0.8272 - val_loss: 0.4843 - val_acc: 0.8390\n",
            "Epoch 19/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4814 - acc: 0.8347 - val_loss: 0.4985 - val_acc: 0.8348\n",
            "Epoch 20/200\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.4722 - acc: 0.8363 - val_loss: 0.5522 - val_acc: 0.8195\n",
            "Epoch 21/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4602 - acc: 0.8410 - val_loss: 0.5031 - val_acc: 0.8342\n",
            "Epoch 22/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4469 - acc: 0.8474 - val_loss: 0.5061 - val_acc: 0.8352\n",
            "Epoch 23/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4350 - acc: 0.8494 - val_loss: 0.4975 - val_acc: 0.8387\n",
            "Epoch 24/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4240 - acc: 0.8541 - val_loss: 0.4694 - val_acc: 0.8445\n",
            "Epoch 25/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4153 - acc: 0.8568 - val_loss: 0.4474 - val_acc: 0.8544\n",
            "Epoch 26/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4017 - acc: 0.8611 - val_loss: 0.4883 - val_acc: 0.8447\n",
            "Epoch 27/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3963 - acc: 0.8630 - val_loss: 0.4960 - val_acc: 0.8411\n",
            "Epoch 28/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3849 - acc: 0.8664 - val_loss: 0.4664 - val_acc: 0.8507\n",
            "Epoch 29/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3777 - acc: 0.8691 - val_loss: 0.5420 - val_acc: 0.8316\n",
            "Epoch 30/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3603 - acc: 0.8753 - val_loss: 0.4833 - val_acc: 0.8472\n",
            "Epoch 31/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3550 - acc: 0.8761 - val_loss: 0.4644 - val_acc: 0.8466\n",
            "Epoch 32/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3518 - acc: 0.8781 - val_loss: 0.4832 - val_acc: 0.8452\n",
            "Epoch 33/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3449 - acc: 0.8796 - val_loss: 0.4424 - val_acc: 0.8581\n",
            "Epoch 34/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3394 - acc: 0.8834 - val_loss: 0.4890 - val_acc: 0.8472\n",
            "Epoch 35/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3328 - acc: 0.8845 - val_loss: 0.4586 - val_acc: 0.8560\n",
            "Epoch 36/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3255 - acc: 0.8860 - val_loss: 0.4391 - val_acc: 0.8595\n",
            "Epoch 37/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3161 - acc: 0.8899 - val_loss: 0.4688 - val_acc: 0.8546\n",
            "Epoch 38/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3097 - acc: 0.8931 - val_loss: 0.4604 - val_acc: 0.8590\n",
            "Epoch 39/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3051 - acc: 0.8940 - val_loss: 0.4628 - val_acc: 0.8608\n",
            "Epoch 40/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3019 - acc: 0.8947 - val_loss: 0.4571 - val_acc: 0.8576\n",
            "Epoch 41/200\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.2912 - acc: 0.8988 - val_loss: 0.4852 - val_acc: 0.8493\n",
            "Epoch 42/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.2834 - acc: 0.9022 - val_loss: 0.4654 - val_acc: 0.8626\n",
            "Epoch 43/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.2904 - acc: 0.8988 - val_loss: 0.4433 - val_acc: 0.8584\n",
            "Epoch 44/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.2823 - acc: 0.9026 - val_loss: 0.4489 - val_acc: 0.8620\n",
            "Epoch 45/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.2771 - acc: 0.9049 - val_loss: 0.4480 - val_acc: 0.8608\n",
            "Epoch 46/200\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.2673 - acc: 0.9068 - val_loss: 0.4636 - val_acc: 0.8636\n",
            "Epoch 00046: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WQ0KnfOzBfh"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaH8e17ceHfR",
        "outputId": "575c6d16-e649-4296-a8d0-f0d750ebe97d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.load_weights(filepath)\n",
        "metrics = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print('Loss = ' + str(metrics[0]))\n",
        "print('Accuracy = ' + str(metrics[1]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.4390917122364044\n",
            "Accuracy = 0.859499990940094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8KdlrHD3Jqv"
      },
      "source": [
        "Per [benchmark.ai](https://benchmarks.ai/cifar-10), the SOTA is 99.37%.\n",
        "\n",
        "Loss = 0.4390917122364044\n",
        "\n",
        "Accuracy = 0.859499990940094"
      ]
    }
  ]
}